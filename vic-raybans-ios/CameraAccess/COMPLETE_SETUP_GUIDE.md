# Complete Setup Guide - Ray-Ban + iOS App + Backend

## üéØ Overview

This guide will help you:
1. ‚úÖ Set up Xcode project
2. ‚úÖ Configure Meta Wearables DAT SDK (for Ray-Ban)
3. ‚úÖ Connect iOS app to backend
4. ‚úÖ Test Ray-Ban integration
5. ‚úÖ Test full flow (Glasses ‚Üí iOS ‚Üí Backend)

---

## Step 1: Open Project in Xcode

```bash
cd "/Users/sheilawang/Desktop/RealityHacks26/samples/CameraAccess"
open CameraAccess.xcodeproj
```

---

## Step 2: Configure Xcode Project Settings

### 2.1 Signing & Capabilities

1. **Select Project** in Xcode (top of left sidebar)
2. **Select "CameraAccess" target**
3. **Go to "Signing & Capabilities" tab**
4. **Enable "Automatically manage signing"**
5. **Select your Team** (your Apple ID)
   - If you don't have a team, click "Add Account"
   - Sign in with your Apple ID
   - Free tier works for testing on your own device

### 2.2 Bundle Identifier

1. Still in **Signing & Capabilities**
2. **Bundle Identifier**: Change to something unique
   - Example: `com.yourname.realityhacks` or `com.yourname.cameraaccess`
   - Must be unique (not used by other apps)

### 2.3 Deployment Target

1. **General tab** ‚Üí **Minimum Deployments**
2. Set **iOS** to **17.0** (required for Meta Wearables DAT SDK)

---

## Step 3: Configure Meta Wearables DAT SDK

### 3.1 Get Meta Developer Credentials

You need to register your app with Meta to get:
- **Client Token**
- **Meta App ID**

**Option A: Use Meta Developer Portal** (Recommended for production)
1. Go to: https://developers.facebook.com/
2. Create a Meta Developer account
3. Create a new app
4. Get your **App ID** and **Client Token**

**Option B: Use Default/Test Values** (For development/testing)
- For testing, you can use placeholder values initially
- The SDK may work with default values for development

### 3.2 Set Environment Variables in Xcode

1. **Select Project** ‚Üí **CameraAccess target** ‚Üí **Build Settings**
2. Search for: `CLIENT_TOKEN`
3. Add User-Defined Setting:
   - **Key**: `CLIENT_TOKEN`
   - **Value**: Your Meta Client Token (or placeholder for testing)

4. **Team ID** is automatically set from your Apple Developer Team

### 3.3 Update Info.plist (if needed)

The `Info.plist` already has the MWDAT configuration:
```xml
<key>MWDAT</key>
<dict>
    <key>AppLinkURLScheme</key>
    <string>cameraaccess://</string>
    <key>ClientToken</key>
    <string>$(CLIENT_TOKEN)</string>
    <key>MetaAppID</key>
    <string>0</string>  <!-- Update this with your App ID -->
    <key>TeamID</key>
    <string>$(DEVELOPMENT_TEAM)</string>
</dict>
```

**To update MetaAppID:**
1. Open `Info.plist` in Xcode
2. Find `MetaAppID` (currently `0`)
3. Change to your Meta App ID (if you have one)
4. For testing, `0` might work with Mock Device Kit

---

## Step 4: Connect iPhone to Mac

1. **Connect iPhone** to Mac via USB cable
2. **Unlock iPhone** and trust the computer if prompted
3. **In Xcode**: Select your iPhone from device dropdown (top toolbar)
   - Should show: "iPhone (iOS XX.X)"

---

## Step 5: Enable Developer Mode on iPhone

1. **On iPhone**: Go to **Settings** ‚Üí **Privacy & Security**
2. Scroll down to **Developer Mode**
3. **Toggle ON** Developer Mode
4. **Restart iPhone** if prompted

---

## Step 6: Enable Meta AI Developer Mode

1. **Install Meta AI App** on iPhone (from App Store)
2. **Open Meta AI app**
3. **Sign in** with your Meta account
4. **Go to Settings** ‚Üí **Developer Mode**
5. **Toggle Developer Mode ON**
6. **Pair your Ray-Ban glasses** with Meta AI app (if you have them)

---

## Step 7: Configure Backend Connection

The app already has backend integration code. You need to set the user ID:

### Option A: Hardcode User ID (Quick Test)

Edit `MemoryCaptureWebSocketClient.swift`:
```swift
var userId: String = "your_user_id_here"  // Line 24
```

### Option B: Add Settings UI (Better)

Create a settings screen to let user enter their ID.

**For now, let's update the default:**

1. Open: `samples/CameraAccess/CameraAccess/Utils/MemoryCaptureWebSocketClient.swift`
2. Find line 24: `var userId: String = ""`
3. Change to: `var userId: String = "test_user"` (or your actual user ID)

---

## Step 8: Build and Run on iPhone

1. **In Xcode**: Press `Cmd + B` to build
2. **Fix any errors** if they appear
3. **Press `Cmd + R`** to run on iPhone
4. **First time**: iPhone will ask to trust developer
   - Go to: **Settings** ‚Üí **General** ‚Üí **VPN & Device Management**
   - Trust your developer certificate
5. **App launches** on iPhone!

---

## Step 9: Connect to Ray-Ban Glasses

### 9.1 Using Real Glasses

1. **Launch your app** on iPhone
2. **Press "Connect" button**
3. **App redirects to Meta AI app**
4. **Authorize** the connection in Meta AI app
5. **Returns to your app**
6. **Grant permissions**:
   - Camera permission
   - Microphone permission
   - Bluetooth permission
7. **Start streaming** - you should see live video from glasses!

### 9.2 Using Mock Device (Testing Without Glasses)

The app includes **Mock Device Kit** for testing:

1. **Launch app** in DEBUG mode
2. **Look for debug menu** (usually a button or gesture)
3. **Enable Mock Device**
4. **Simulate glasses connection**
5. **Test all features** except hardware-specific ones

---

## Step 10: Test Backend Integration

### 10.1 Test Memory Capture

1. **Start streaming** from glasses
2. **Capture a photo** (camera button)
3. **App should**:
   - Upload photo to backend via `POST /upload/{captureId}`
   - Send memory capture via WebSocket `/ws/ios/{userId}`
   - Receive acknowledgment

### 10.2 Verify Backend Connection

Check backend logs or use the test script:
```bash
cd "/Users/sheilawang/Desktop/RealityHacks26/samples/CameraAccess"
swift test_backend.swift
```

---

## Step 11: Full Integration Test

### Test Flow:

```
1. Ray-Ban Glasses ‚Üí Capture Photo
   ‚Üì
2. iOS App ‚Üí Upload to Backend
   ‚Üì
3. Backend ‚Üí Process with Gemini AI
   ‚Üì
4. Backend ‚Üí Update Contacts Database
   ‚Üì
5. Caretaker App ‚Üí View People Profiles
```

### Steps:

1. **Capture photo** from glasses in iOS app
2. **Check backend** - photo should be uploaded
3. **Wait for processing** - backend analyzes with Gemini
4. **Check contacts** - new people should appear
5. **Open Caretaker App** - should see updated people profiles

---

## üîß Configuration Checklist

- [ ] Xcode project opened
- [ ] Signing & Capabilities configured (Team selected)
- [ ] Bundle Identifier set (unique)
- [ ] iOS deployment target: 17.0+
- [ ] CLIENT_TOKEN set (or placeholder)
- [ ] MetaAppID set (or 0 for testing)
- [ ] iPhone connected to Mac
- [ ] Developer Mode enabled on iPhone
- [ ] Meta AI app installed on iPhone
- [ ] Developer Mode enabled in Meta AI app
- [ ] Ray-Ban glasses paired (or Mock Device enabled)
- [ ] Backend user ID configured
- [ ] App built and installed on iPhone
- [ ] Permissions granted (Camera, Microphone, Bluetooth)

---

## üß™ Testing Scenarios

### Scenario 1: Test Without Glasses (Mock Device)

1. Use Mock Device Kit in DEBUG mode
2. Simulate photo capture
3. Test backend upload
4. Verify WebSocket connection

### Scenario 2: Test With Real Glasses

1. Connect real Ray-Ban glasses
2. Stream live video
3. Capture actual photos
4. Test full backend integration

### Scenario 3: Test Backend Only

1. Use test script: `swift test_backend.swift`
2. Test WebSocket connections
3. Verify API endpoints
4. Check data flow

---

## üêõ Troubleshooting

### "Device Not Found"
- ‚úÖ Check glasses are paired with Meta AI app
- ‚úÖ Check Bluetooth is enabled
- ‚úÖ Restart both apps
- ‚úÖ Try Mock Device for testing

### "Registration Failed"
- ‚úÖ Check Developer Mode is ON in Meta AI app
- ‚úÖ Check you're signed in to Meta AI app
- ‚úÖ Verify CLIENT_TOKEN is set (even if placeholder)
- ‚úÖ Try disconnecting and reconnecting

### "Permission Denied"
- ‚úÖ Go to iPhone Settings ‚Üí Your App
- ‚úÖ Enable Camera and Microphone permissions

### "Backend Connection Failed"
- ‚úÖ Check backend URL is correct
- ‚úÖ Verify user ID is set
- ‚úÖ Check network connection
- ‚úÖ Test backend with: `swift test_backend.swift`

### "Build Failed"
- ‚úÖ Check Xcode version (14.0+)
- ‚úÖ Update Meta Wearables DAT SDK if needed
- ‚úÖ Clean build: `Cmd + Shift + K`, then rebuild

---

## üì± Quick Test Commands

```bash
# Test backend connection
cd "/Users/sheilawang/Desktop/RealityHacks26/samples/CameraAccess"
swift test_backend.swift

# Check if backend is running
curl https://memory-backend-328251955578.us-east1.run.app/

# Test WebSocket (requires Node.js)
# Or use the Swift test script above
```

---

## üéØ Next Steps After Setup

1. **Test basic connection**: Glasses ‚Üí iOS app
2. **Test photo capture**: Capture ‚Üí Upload ‚Üí Backend
3. **Test memory capture**: WebSocket ‚Üí Backend processing
4. **Test people detection**: Backend ‚Üí Contacts update
5. **Test caretaker app**: View people profiles

---

## üìö Resources

- **Meta Wearables DAT SDK Docs**: https://wearables.developer.meta.com/docs/develop/
- **Meta Developer Portal**: https://developers.facebook.com/
- **Apple Developer Docs**: https://developer.apple.com/documentation/
- **Backend API Docs**: See `Backend/send_data.md` and `Backend/query_data.md`

---

## ‚úÖ Success Indicators

You'll know everything is working when:

1. ‚úÖ App builds without errors
2. ‚úÖ App installs on iPhone
3. ‚úÖ "Connect" button works
4. ‚úÖ Glasses connect (or Mock Device works)
5. ‚úÖ Video streams from glasses
6. ‚úÖ Photos can be captured
7. ‚úÖ Backend receives uploads
8. ‚úÖ WebSocket sends memory captures
9. ‚úÖ Backend processes with Gemini
10. ‚úÖ People profiles update in backend

---

Ready to test! Let me know if you hit any issues during setup. üöÄ
